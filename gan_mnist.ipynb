{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist_data = input_data.read_data_sets('MNIST_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 784)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1211ca550>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADpdJREFUeJzt3XGMVeWZx/HfA1KClhC1SibW3WEbs1IxUJzIxoCirgja\nZOgfmpqo1DZSk5osSROLrromZiMx4kYTLA4pdrrp2m5QIiHrFiQbZHVTHUlFxaUgTgNkYFAkpX8o\nIs/+MYfNiHPec7nn3nvuzPP9JJO59zz33PNwMz/Ovfc957zm7gIQz7iqGwBQDcIPBEX4gaAIPxAU\n4QeCIvxAUIQfCIrwA0ERfiCos1q5MTPjcEKgydzdanlcqT2/mS00s11mtsfMlpd5LgCtZfUe229m\n4yX9UdINkvZLelPSbe6+M7EOe36gyVqx579S0h533+vuxyX9RlJ3iecD0EJlwn+RpH3D7u/Pln2J\nmS01sz4z6yuxLQAN1vQv/Ny9R1KPxNt+oJ2U2fMfkHTxsPvfzJYBGAXKhP9NSZeY2TQz+5qk70va\n0Ji2ADRb3W/73f2Emd0r6XeSxkta6+7vNawzAE1V91BfXRvjMz/QdC05yAfA6EX4gaAIPxAU4QeC\nIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEH\ngiL8QFAtnaIb8UycODG3dvfddyfXfeqpp5L1cePS+6577rknt/bss88m142APT8QFOEHgiL8QFCE\nHwiK8ANBEX4gKMIPBFVqll4z65d0TNIXkk64e1fB45mld4yZNGlSsv7000/n1u66665S2zZLT0b7\n9ttv59Zmz55datvtrNZZehtxkM+17v5RA54HQAvxth8Iqmz4XdImM3vLzJY2oiEArVH2bf9cdz9g\nZhdK2mxm/+vurw5/QPafAv8xAG2m1J7f3Q9kvwclrZd05QiP6XH3rqIvAwG0Vt3hN7NzzGzyqduS\nFkh6t1GNAWiuMm/7p0panw23nCXp39z9PxvSFYCmqzv87r5X0swG9oI2NGvWrGR91apVyfqcOXMa\n2c4ZmTx5cm7t/PPPT6778ccfN7qdtsNQHxAU4QeCIvxAUIQfCIrwA0ERfiCoUqf0nvHGOKW37axY\nsSJZLzrttmjIrJmKTulN/W0vWrQoue7mzZvr6qkd1HpKL3t+ICjCDwRF+IGgCD8QFOEHgiL8QFCE\nHwiKKbrHgM7Oztzahg0bkuteeumlyfr48eOT9aLjRNatW5dbe/TRR5Pr3nLLLcn6Qw89lKwfPnw4\nt/bhhx8m142APT8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBMU4/ygwc2b6Cunbt29v2rYHBweT9eXL\nlyfrvb29dW+76FoD48al910HDx7Mre3Zs6eunsYS9vxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EFTh\nOL+ZrZX0XUmD7j4jW3aepN9K6pTUL+lWd/+keW0ipczcC0Xj8CtXrkzWd+7cWfe2586dm6zPnz8/\nWT958mSyvnHjxjNtKZRa9vy/lLTwtGXLJW1x90skbcnuAxhFCsPv7q9KOnLa4m5Jp3YZvZIWN7gv\nAE1W72f+qe4+kN0+KGlqg/oB0CKlj+13d0/NwWdmSyUtLbsdAI1V757/kJl1SFL2O/fsD3fvcfcu\nd++qc1sAmqDe8G+QtCS7vUTSS41pB0CrFIbfzJ6X9D+S/tbM9pvZjyStkHSDme2W9PfZfQCjSOFn\nfne/Lad0fYN7QY69e/cm60Vzzads3bo1WT9+/Hjdz11k2rRpyfqkSZNKPf+uXbtKrT/WcYQfEBTh\nB4Ii/EBQhB8IivADQRF+ICgu3T0KHDt2LFnfvHlzizpprOnTp5da/9NPP03Wi4ZIo2PPDwRF+IGg\nCD8QFOEHgiL8QFCEHwiK8ANBMc6Ppurs7Myt3XHHHaWee8uWLcn666+/Xur5xzr2/EBQhB8IivAD\nQRF+ICjCDwRF+IGgCD8QlJWZ3vmMN5aY1ms0K7rE9PXXp69y3tWVnsxo9erVyfpnn32WW/vkk+bO\nnD5hwoRkfdOmTbm1q6++utS2x48fX2r9scrdrZbHsecHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAK\nz+c3s7WSvitp0N1nZMsekXS3pMPZwx5w9/9oVpPtYMaMGbm1Z555JrnuVVddlaybpYdlH3zwwWR9\nYGAgt7Zq1arkui+//HKyvnPnzmS9u7s7WZ83b15uregYk97e3mQd5dSy5/+lpIUjLP8Xd5+V/Yzp\n4ANjUWH43f1VSUda0AuAFirzmf9eM9thZmvN7NyGdQSgJeoN/88lfUvSLEkDklbmPdDMlppZn5n1\n1bktAE1QV/jd/ZC7f+HuJyWtkXRl4rE97t7l7umzVwC0VF3hN7OOYXe/J+ndxrQDoFVqGep7XtJ8\nSd8ws/2S/knSfDObJckl9Uv6cRN7BNAEnM+fmTx5crL+3HPP5dYWL16cXHfr1q3J+ueff56sX3bZ\nZcl6R0dHsl7Gtm3bkvXUOH6R1PEJknT55Zcn60ePHq1722MZ5/MDSCL8QFCEHwiK8ANBEX4gKMIP\nBMVQX+aJJ55I1pctW5Zbe/zxx5PrPvzww8n6iRMnkvXZs2cn64899lhureiy4UWKTjcu8/dTNFS3\nb9++ZP3JJ59M1lOXLd+4cWNy3dGMoT4ASYQfCIrwA0ERfiAowg8ERfiBoAg/EFSYcf4LL7wwWf/g\ngw+S9TfeeCO3duONNybXLRrHL2vixIm5tSlTpiTX3bFjR7J+wQUXJOut/Ps5XdExCKlTpY8cKXdN\n2pkzZybrhw8fTtabiXF+AEmEHwiK8ANBEX4gKMIPBEX4gaAIPxBU4XX7x4prr702WT/77LOT9Vde\neSW31uxx/DKKrjVQNI4/blx6/7B79+5kvaenJ7c2ffr05LqLFi1K1stca2DdunXJdYumLq9yHL9R\n2PMDQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCF4/xmdrGkX0maKskl9bj7U2Z2nqTfSuqU1C/pVnfP\nv1B6xa644opkvei89L6+vka28yUTJkxI1q+55ppk/b777sutXXfddcl1i/7dReP4CxYsSNb7+/uT\ndVSnlj3/CUk/dfdvS/o7ST8xs29LWi5pi7tfImlLdh/AKFEYfncfcPft2e1jkt6XdJGkbkm92cN6\nJS1uVpMAGu+MPvObWaek70j6vaSp7j6QlQ5q6GMBgFGi5mP7zezrkl6QtMzd/zz8uGp397zr85nZ\nUklLyzYKoLFq2vOb2QQNBf/X7v5itviQmXVk9Q5JgyOt6+497t7l7l2NaBhAYxSG34Z28b+Q9L67\nD58WdYOkJdntJZJeanx7AJql8NLdZjZX0jZJ70g6mS1+QEOf+/9d0l9J+pOGhvqS10Ou8tLdc+bM\nSdZfe+21ZH39+vW5tTVr1tTV0yn3339/sj5v3rxSz59SNDX56tWrk3WG8tpPrZfuLvzM7+7/LSnv\nycpN/g6gMhzhBwRF+IGgCD8QFOEHgiL8QFCEHwgqzBTdRafNFl3K+eabb25kO19S5hLUkjQwMJBb\nu/POO5Prbtu2LVlv58uSY2RM0Q0gifADQRF+ICjCDwRF+IGgCD8QFOEHggozzl9kypQpyfrtt9+e\nW1u4cGFy3aKppru7u5P1IqlrERw9erTUc2P0YZwfQBLhB4Ii/EBQhB8IivADQRF+ICjCDwTFOD8w\nxjDODyCJ8ANBEX4gKMIPBEX4gaAIPxAU4QeCKgy/mV1sZv9lZjvN7D0z+4ds+SNmdsDM/pD93NT8\ndgE0SuFBPmbWIanD3beb2WRJb0laLOlWSX9x9ydq3hgH+QBNV+tBPmfV8EQDkgay28fM7H1JF5Vr\nD0DVzugzv5l1SvqOpN9ni+41sx1mttbMzs1ZZ6mZ9ZlZX6lOATRUzcf2m9nXJW2V9M/u/qKZTZX0\nkSSX9KiGPhr8sOA5eNsPNFmtb/trCr+ZTZC0UdLv3P3JEeqdkja6+4yC5yH8QJM17MQeG5pC9heS\n3h8e/OyLwFO+J+ndM20SQHVq+bZ/rqRtkt6RdDJb/ICk2yTN0tDb/n5JP86+HEw9F3t+oMka+ra/\nUQg/0Hyczw8gifADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxBU\n4QU8G+wjSX8adv8b2bJ21K69tWtfEr3Vq5G9/XWtD2zp+fxf2bhZn7t3VdZAQrv21q59SfRWr6p6\n420/EBThB4KqOvw9FW8/pV17a9e+JHqrVyW9VfqZH0B1qt7zA6hIJeE3s4VmtsvM9pjZ8ip6yGNm\n/Wb2TjbzcKVTjGXToA2a2bvDlp1nZpvNbHf2e8Rp0irqrS1mbk7MLF3pa9duM163/G2/mY2X9EdJ\nN0jaL+lNSbe5+86WNpLDzPoldbl75WPCZna1pL9I+tWp2ZDM7HFJR9x9RfYf57nu/rM26e0RneHM\nzU3qLW9m6R+owteukTNeN0IVe/4rJe1x973uflzSbyR1V9BH23P3VyUdOW1xt6Te7Havhv54Wi6n\nt7bg7gPuvj27fUzSqZmlK33tEn1VoorwXyRp37D7+9VeU367pE1m9paZLa26mRFMHTYz0kFJU6ts\nZgSFMze30mkzS7fNa1fPjNeNxhd+XzXX3WdLWiTpJ9nb27bkQ5/Z2mm45ueSvqWhadwGJK2sspls\nZukXJC1z9z8Pr1X52o3QVyWvWxXhPyDp4mH3v5ktawvufiD7PShpvYY+prSTQ6cmSc1+D1bcz/9z\n90Pu/oW7n5S0RhW+dtnM0i9I+rW7v5gtrvy1G6mvql63KsL/pqRLzGyamX1N0vclbaigj68ws3Oy\nL2JkZudIWqD2m314g6Ql2e0lkl6qsJcvaZeZm/NmllbFr13bzXjt7i3/kXSThr7x/0DSP1bRQ05f\nfyPp7eznvap7k/S8ht4Gfq6h70Z+JOl8SVsk7Zb0iqTz2qi3f9XQbM47NBS0jop6m6uht/Q7JP0h\n+7mp6tcu0VclrxtH+AFB8YUfEBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGg/g8bFslFN/vbqwAA\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11504c160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_image = mnist_data.train.next_batch(1)[0]\n",
    "print(sample_image.shape)\n",
    "sample_image = sample_image.reshape([28,28])\n",
    "plt.imshow(sample_image, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator(images, reuse=False):\n",
    "    with tf.variable_scope(tf.get_variable_scope(), reuse=reuse) as scope:\n",
    "    \n",
    "        # First Convolutional and pool layers\n",
    "        # This finds 32 different 5*5 features\n",
    "        d_w1 = tf.get_variable('d_w1', [5, 5, 1, 32], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        d_b1 = tf.get_variable('d_b1', [32], initializer=tf.constant_initializer(0))\n",
    "        d1 = tf.nn.conv2d(input=images, filter=d_w1, strides=[1,1,1,1], padding='SAME')\n",
    "        d1 = d1 + d_b1\n",
    "        d1 = tf.nn.relu(d1)\n",
    "        d1 = tf.nn.avg_pool(d1, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "\n",
    "        # Second Convolutional layer\n",
    "        d_w2 = tf.get_variable('d_w2', [5, 5, 32, 64], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        d_b2 = tf.get_variable('d_b2', [64], initializer=tf.constant_initializer(0))\n",
    "        d2 = tf.nn.conv2d(input=d1, filter=d_w2, strides=[1,1,1,1], padding='SAME')\n",
    "        d2 = d2 + d_b2\n",
    "        d2 = tf.nn.relu(d2)\n",
    "        d2 = tf.nn.avg_pool(d2, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "\n",
    "        # First Fully Connected layer\n",
    "        d_w3 = tf.get_variable('d_w3', [7*7*64, 1024], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        d_b3 = tf.get_variable('d_b3', [1024], initializer=tf.constant_initializer(0))\n",
    "        d3 = tf.reshape(d2, [-1, 7*7*64]) # Flatten\n",
    "        d3 = tf.matmul(d3, d_w3)\n",
    "        d3 = d3 + d_b3\n",
    "        d3 = tf.nn.relu(d3)\n",
    "\n",
    "        # Last Output layer\n",
    "        d_w4 = tf.get_variable('d_w4', [1024, 1], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        d_b4 = tf.get_variable('d_b4', [1], initializer=tf.constant_initializer(0))\n",
    "        d4 = tf.matmul(d3, d_w4) + d_b4\n",
    "\n",
    "        return d4\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(z, batch_size, z_dim):\n",
    "    g_w1 = tf.get_variable('g_w1', [z_dim, 3136], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02)) # 3136 = 28*28*2*2\n",
    "    g_b1 = tf.get_variable('g_b1', [3136], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g1 = tf.matmul(z, g_w1) + g_b1\n",
    "    g1 = tf.reshape(g1, [-1, 56, 56, 1])\n",
    "    g1 = tf.contrib.layers.batch_norm(g1, epsilon=1e-5, scope='bn1')\n",
    "    g1 = tf.nn.relu(g1)\n",
    "    \n",
    "    # Generate 50 features\n",
    "    g_w2 = tf.get_variable('g_w2', [3, 3, 1, z_dim/2], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b2 = tf.get_variable('g_b2', [z_dim/2], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g2 = tf.nn.conv2d(g1, g_w2, strides=[1, 2, 2, 1], padding='SAME')\n",
    "    g2 = g2 + g_b2\n",
    "    g2 = tf.contrib.layers.batch_norm(g2, epsilon=1e-5, scope='bn2')\n",
    "    g2 = tf.nn.relu(g2)\n",
    "    g2 = tf.image.resize_images(g2, [56, 56])\n",
    "    \n",
    "    # Generate 25 features\n",
    "    g_w3 = tf.get_variable('g_w3', [3, 3, z_dim/2, z_dim/4], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b3 = tf.get_variable('g_b3', [z_dim/4], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g3 = tf.nn.conv2d(g2, g_w3, strides=[1,2,2,1], padding='SAME')\n",
    "    g3 = g3 + g_b3\n",
    "    g3 = tf.contrib.layers.batch_norm(g3, epsilon=1e-5, scope='bn3')\n",
    "    g3 = tf.nn.relu(g3)\n",
    "    g3 = tf.image.resize_images(g3, [56, 56])\n",
    "    \n",
    "    # Final convolution with one output channel\n",
    "    g_w4 = tf.get_variable('g_w4', [1, 1, z_dim/4, 1], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b4 = tf.get_variable('g_b4', [1], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g4 = tf.nn.conv2d(g3, g_w4, strides=[1, 2, 2, 1], padding='SAME')\n",
    "    g4 = g4 + g_b4\n",
    "    g4 = tf.sigmoid(g4)\n",
    "    \n",
    "    # Dimension of g4: batch_size * 28 * 28 * 1\n",
    "    return g4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Image Generating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z_dimensions = 100 \n",
    "z_placeholder = tf.placeholder(tf.float32, [None, z_dimensions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generated_image_output = generator(z_placeholder, 1, z_dimensions)\n",
    "z_batch = np.random.normal(0, 1, [1, z_dimensions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUvGLJErFL5IoFb9IolT8Ion6P+FatH2YbTpvAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1149b2fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    generated_image = sess.run(generated_image_output, feed_dict={z_placeholder:z_batch})\n",
    "    generated_image = generated_image.reshape([28, 28])\n",
    "    plt.imshow(generated_image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training GAN with MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "batch_size = 50\n",
    "\n",
    "# z_placeholder is for feeding input noise to the \"generator\"\n",
    "z_placeholder = tf.placeholder(tf.float32, [None, z_dimensions], name='z_placeholder')\n",
    "# x_placeholder is for feeding input images to the \"discriminator\"\n",
    "x_placeholder = tf.placeholder(tf.float32, [None, 28, 28, 1], name='x_placeholder')\n",
    "\n",
    "# Gz holds the generated images\n",
    "Gz = generator(z_placeholder, batch_size, z_dimensions)\n",
    "\n",
    "# Dx will hold discriminator prediction probabilities\n",
    "# for the real MNIST images\n",
    "Dx = discriminator(x_placeholder)\n",
    "\n",
    "# Dg will hold discriminator prediction probabilities for generated images\n",
    "Dg = discriminator(Gz, reuse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Discriminator Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compare real images loss probabilities : 1 <-> Dx output\n",
    "# tf.ones_like : Make same shape of 1 matrix\n",
    "d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Dx, labels=tf.ones_like(Dx)))\n",
    "\n",
    "# Compare fake images loss probabilities : 0 <-> Dg outut\n",
    "d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Dg, labels=tf.zeros_like(Dg)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Generator Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generator wants the discriminator to output a value close to 1 when it's given an image from the generator\n",
    "g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Dg, labels=tf.ones_like(Dg)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure out training variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'd_w1:0' shape=(5, 5, 1, 32) dtype=float32_ref>, <tf.Variable 'd_b1:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'd_w2:0' shape=(5, 5, 32, 64) dtype=float32_ref>, <tf.Variable 'd_b2:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'd_w3:0' shape=(3136, 1024) dtype=float32_ref>, <tf.Variable 'd_b3:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'd_w4:0' shape=(1024, 1) dtype=float32_ref>, <tf.Variable 'd_b4:0' shape=(1,) dtype=float32_ref>]\n",
      "[<tf.Variable 'g_w1:0' shape=(100, 3136) dtype=float32_ref>, <tf.Variable 'g_b1:0' shape=(3136,) dtype=float32_ref>, <tf.Variable 'g_w2:0' shape=(3, 3, 1, 50) dtype=float32_ref>, <tf.Variable 'g_b2:0' shape=(50,) dtype=float32_ref>, <tf.Variable 'g_w3:0' shape=(3, 3, 50, 25) dtype=float32_ref>, <tf.Variable 'g_b3:0' shape=(25,) dtype=float32_ref>, <tf.Variable 'g_w4:0' shape=(1, 1, 25, 1) dtype=float32_ref>, <tf.Variable 'g_b4:0' shape=(1,) dtype=float32_ref>]\n"
     ]
    }
   ],
   "source": [
    "tvars = tf.trainable_variables()\n",
    "d_tvars = [var for var in tvars if 'd_' in var.name]\n",
    "g_tvars = [var for var in tvars if 'g_' in var.name]\n",
    "\n",
    "print(d_tvars)\n",
    "print(g_tvars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_trainer_real = tf.train.AdamOptimizer(0.0003).minimize(d_loss_real, var_list=d_tvars)\n",
    "d_trainer_fake = tf.train.AdamOptimizer(0.0003).minimize(d_loss_fake, var_list=d_tvars)\n",
    "\n",
    "# Train Generator\n",
    "g_trainer = tf.train.AdamOptimizer(0.0001).minimize(g_loss, var_list=g_tvars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.get_variable_scope().reuse_variables()\n",
    "\n",
    "tf.summary.scalar('Generator_loss', g_loss)\n",
    "tf.summary.scalar('Discriminator_loss_fake', d_loss_fake)\n",
    "tf.summary.scalar('Discriminator_loss_real', d_loss_real)\n",
    "\n",
    "images_for_tensorboard = generator(z_placeholder, batch_size, z_dimensions)\n",
    "tf.summary.image('Generated_Image', images_for_tensorboard, 5)\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "logdir = \"tensorboard/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + '/'\n",
    "writer = tf.summary.FileWriter(logdir, sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator loss Real : 0.694429337978363, loss Fake : 0.710320234298706\n",
      "Discriminator loss Real : 0.21739596128463745, loss Fake : 0.31295689940452576\n",
      "Discriminator loss Real : 0.0007694261730648577, loss Fake : 0.0011266965884715319\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(300):\n",
    "    z_batch = np.random.normal(0, 1, [batch_size, z_dimensions])\n",
    "    real_image_batch = mnist_data.train.next_batch(batch_size)[0].reshape([batch_size, 28, 28, 1])\n",
    "    _, _, dLossReal, dLossFake = sess.run([d_trainer_real, d_trainer_fake, d_loss_real, d_loss_fake], \n",
    "                                          feed_dict={z_placeholder:z_batch, x_placeholder:real_image_batch})\n",
    "    if i % 100 == 0:\n",
    "        print(\"Discriminator loss Real : {}, loss Fake : {}\".format(dLossReal, dLossFake))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
